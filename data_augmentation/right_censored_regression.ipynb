{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stanford heart transplant censored data study\n",
    "\n",
    "## TRUNCATE THE DATA SO THAT THERE ARE MORE EFFECTS DOWNSTREAM WITH THE POSTERIOR DISTRIBUTIONS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(40) # For reproducibility\n",
    "\n",
    "stanfordHeartData = pd.read_csv('heart_transplant.csv')\n",
    "\n",
    "# Regressing log survival time on age to get sample variance of errors\n",
    "\n",
    "aliveIndices = stanfordHeartData.index[stanfordHeartData['survived'] == 'alive'].tolist()\n",
    "deadIndices = stanfordHeartData.index[stanfordHeartData['survived'] == 'dead'].tolist()\n",
    "# Truncate the data \n",
    "truncatedAlive = 28\n",
    "truncatedDead = 20\n",
    "aliveIndices = random.sample(aliveIndices, truncatedAlive)\n",
    "deadIndices = random.sample(deadIndices, truncatedDead)\n",
    "\n",
    "deadSurvivalTimes = stanfordHeartData['survtime'][deadIndices]\n",
    "logDeadSurvivalTimes = np.array(np.log(deadSurvivalTimes))\n",
    "deadAge = np.array(stanfordHeartData['age'][deadIndices])\n",
    "\n",
    "aliveCensoredEventTimes = stanfordHeartData['survtime'][aliveIndices]\n",
    "logAliveCensoredEventTimes = np.array(np.log(aliveCensoredEventTimes))\n",
    "aliveAge = np.array(stanfordHeartData['age'][aliveIndices])\n",
    "numCensoredEventTimes = len(aliveCensoredEventTimes)\n",
    "allAge = np.append(deadAge.reshape(-1, 1), aliveAge.reshape(-1, 1), 0)\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "# Reshape the arrays\n",
    "\n",
    "deadAgeReshaped = deadAge.reshape(-1, 1)\n",
    "logDeadSurvivalTimesReshaped = logDeadSurvivalTimes.reshape(-1, 1)\n",
    "\n",
    "model.fit(deadAgeReshaped, logDeadSurvivalTimesReshaped)\n",
    "beta0 = model.intercept_[0]\n",
    "beta1 = model.coef_[0][0]\n",
    "yHat = model.predict(deadAgeReshaped)\n",
    "residuals = yHat - logDeadSurvivalTimesReshaped # Flatten the predicted values\n",
    "nonAugmentedResidualVariance = np.var(residuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw o^2* from the chi square distribution\n",
    "\n",
    "numObservedData = len(deadSurvivalTimes)\n",
    "numIterations = 50\n",
    "numImputations = 5000\n",
    "currentResidualVariance = (numObservedData - 1) * nonAugmentedResidualVariance / np.random.chisquare(numObservedData - 1, numImputations)\n",
    "designMatrix = np.ones([numObservedData, 2])\n",
    "designMatrix[:, 1] = deadAgeReshaped.flatten()\n",
    "jointPosteriorApprox = np.zeros([numImputations, 3])\n",
    "jointPosteriorApprox[:, 2] = currentResidualVariance.reshape(-1, 1).flatten()\n",
    "numTotalDatapoints = len(stanfordHeartData['age'])\n",
    "\n",
    "# Initialize the approximation to the posterior distribution by sampling the error variance\n",
    "# from the linear regression model that does not include the right censored data\n",
    "\n",
    "for iiImputation in range(numImputations):\n",
    "\n",
    "    varStar = currentResidualVariance[iiImputation]\n",
    "    covarianceMatrix = np.linalg.inv(varStar * designMatrix.T @ designMatrix) \n",
    "    tempBetaStars = np.random.multivariate_normal([beta0, beta1], covarianceMatrix, 1).reshape(1, -1)\n",
    "    jointPosteriorApprox[iiImputation, 0:2] = tempBetaStars\n",
    "\n",
    "\n",
    "## Now start the actual algorithm\n",
    "\n",
    "augmentedSurvivalTimes = np.zeros([numCensoredEventTimes, numImputations]) ## row = data point, column = imputation number\n",
    "quantiles = np.array([.025,.50, .975])\n",
    "convergenceBeta0 = np.zeros([len(quantiles), numIterations])\n",
    "convergenceBeta1 = np.zeros([len(quantiles), numIterations])\n",
    "convergenceSigmaSq = np.zeros([len(quantiles), numIterations])\n",
    "\n",
    "for iiIteration in range(numIterations):\n",
    "\n",
    "    if iiIteration % 10 == 0:\n",
    "\n",
    "        print('Iteration: ', iiIteration)\n",
    "\n",
    "    for jjImputation in range(numImputations):\n",
    "\n",
    "        # Randomly select from the mixture of posterior distributions\n",
    "\n",
    "        randomIndex = random.randint(0, numImputations - 1)\n",
    "        thetaStar = jointPosteriorApprox[randomIndex, :]\n",
    "        sigmaSqStar = thetaStar[-1]\n",
    "        beta0Star = thetaStar[0]\n",
    "        beta1Star = thetaStar[1]\n",
    "\n",
    "        # Generate the augmented data by sampling errors and adding to right censored event time\n",
    "\n",
    "        for kkCensoredEventTime in range(numCensoredEventTimes):\n",
    "\n",
    "            predictedSurvivalTime = (beta0Star + beta1Star * aliveAge[kkCensoredEventTime])\n",
    "            predictedError = predictedSurvivalTime - logAliveCensoredEventTimes[kkCensoredEventTime]\n",
    "            drawFromConditionalErroDistribution = np.random.normal(0, sigmaSqStar)\n",
    "\n",
    "            while drawFromConditionalErroDistribution < predictedError:\n",
    "\n",
    "                drawFromConditionalErroDistribution = np.random.normal(0, sigmaSqStar)\n",
    "\n",
    "            augmentedSurvivalTimes[kkCensoredEventTime, jjImputation] = predictedSurvivalTime + drawFromConditionalErroDistribution\n",
    "\n",
    "        # Update the approximation to the posterior \n",
    "        # Randomly select the augmented data to use, then do linear regression, then sample the sigmaSqStar, then beta0 and beta1\n",
    "\n",
    "    for jjImputation in range(numImputations):\n",
    "\n",
    "        randomIndex = random.randint(0, numImputations - 1)\n",
    "        tempAugmentedData = augmentedSurvivalTimes[:, randomIndex]\n",
    "        tempAugmentedDesignMatrix = np.append(np.ones([numCensoredEventTimes, 1]), aliveAge.reshape(-1, 1), 1)\n",
    "        tempTotalDesignMatrix = np.append(designMatrix, tempAugmentedDesignMatrix, 0)\n",
    "        tempAugmentedSurvivalTimes = np.append(logDeadSurvivalTimes.reshape(-1, 1), tempAugmentedData.reshape(-1, 1), 0)\n",
    "\n",
    "        model.fit(tempTotalDesignMatrix[:, -1].reshape(-1, 1), tempAugmentedSurvivalTimes)\n",
    "\n",
    "        ## Need to sample the coefficients from the posteriors for beta0 beta1 sigmaStar from augmented linear model and add to array\n",
    "        # The posterior for the betas is normal centered around the least squares estimates with covar matrix inv(sample o^2 * X_T @ X)\n",
    "        \n",
    "        beta0 = model.intercept_[0]\n",
    "        beta1 = model.coef_[0][0]\n",
    "        yHat = model.predict(tempTotalDesignMatrix[:, -1].reshape(-1, 1))\n",
    "        residuals = yHat - tempAugmentedSurvivalTimes\n",
    "        sampleResidualVariance = np.var(residuals)\n",
    "        sigmaSquaredStar = (numTotalDatapoints - 1) * sampleResidualVariance / np.random.chisquare(numTotalDatapoints - 1, 1)\n",
    "\n",
    "        tempCovarianceMatrix = np.linalg.inv(sigmaSquaredStar * tempTotalDesignMatrix.T @ tempTotalDesignMatrix) \n",
    "        betasStar = np.random.multivariate_normal([beta0, beta1], tempCovarianceMatrix, 1).reshape(1, -1)\n",
    "        jointPosteriorApprox[iiImputation, -1] = sigmaSquaredStar\n",
    "        jointPosteriorApprox[iiImputation, 0:2] = betasStar\n",
    "\n",
    "    convergenceBeta0[:, iiIteration] = np.quantile(jointPosteriorApprox[:, 0], quantiles, axis = 0)\n",
    "    convergenceBeta1[:, iiIteration] = np.quantile(jointPosteriorApprox[:, 1], quantiles, axis = 0)\n",
    "    convergenceSigmaSq[:, iiIteration] = np.quantile(jointPosteriorApprox[:, -1], quantiles, axis = 0)\n",
    "\n",
    "## MAKE LAST SAMPLE FROM POSTERIOR DISTRIBUTION LARGER THAN THE REST, I.E. 10,000 SAMPLES FROM LAST POSTERIOR DISTRIBUTION\n",
    "            \n",
    "## Each iteration gives you an approximation to the posterior distribution\n",
    "## Impute the m = 500 values for augmented data, then with the augmented data, sample from the mixture\n",
    "## of posterior distributions (randomly sample augmented data, use that to calculate and sample from that beta posterior)\n",
    "# So the jointPosteriorApprox matris is exactly that, a sample from the last posterior distribution \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the joint distribution of beta0 and beta1 together\n",
    "\n",
    "beta0Distribution = jointPosteriorApprox[:, 0]\n",
    "beta1Distribution = jointPosteriorApprox[:, 1]\n",
    "\n",
    "print('Covariance for augmented joint posterior: ', np.cov(beta0Distribution, beta1Distribution))\n",
    "\n",
    "plt.scatter(beta1Distribution, beta0Distribution, color = 'black')\n",
    "plt.xlabel('$\\\\beta_1$')\n",
    "plt.ylabel('$\\\\beta_0$')\n",
    "plt.xlim(-.05, .15)\n",
    "plt.ylim(-2, 6)\n",
    "plt.title('Augmented Posterior Joint Distribution Approximation for $\\\\beta_0$ and $\\\\beta_1$')\n",
    "plt.show()\n",
    "\n",
    "model.fit(deadAgeReshaped, logDeadSurvivalTimesReshaped)\n",
    "beta0 = model.intercept_[0]\n",
    "beta1 = model.coef_[0][0]\n",
    "yHat = model.predict(deadAgeReshaped)\n",
    "residuals = yHat - logDeadSurvivalTimesReshaped # Flatten the predicted values\n",
    "nonAugmentedResidualVariance = np.var(residuals)\n",
    "numSamples = 1000\n",
    "nonAugmentedPosteriorApprox = np.zeros([numSamples, 3])\n",
    "\n",
    "\n",
    "for iiSample in range(numSamples):\n",
    "\n",
    "    nonAugmentedSampleResidualVariance = (numObservedData - 1) * nonAugmentedResidualVariance / np.random.chisquare(numObservedData - 1, 1)\n",
    "    nonAugCovarMatrix = np.linalg.inv(nonAugmentedSampleResidualVariance * designMatrix.T @ designMatrix)\n",
    "    betasStar = np.random.multivariate_normal([beta0, beta1], covarianceMatrix, 1).reshape(1, -1)\n",
    "    nonAugmentedPosteriorApprox[iiSample, 0:2] = betasStar\n",
    "    nonAugmentedPosteriorApprox[iiSample, -1] = nonAugmentedSampleResidualVariance\n",
    "\n",
    "beta0Distribution = nonAugmentedPosteriorApprox[:, 0]\n",
    "beta1Distribution = nonAugmentedPosteriorApprox[:, 1]\n",
    "plt.scatter(beta1Distribution, beta0Distribution, color = 'black')\n",
    "plt.xlabel('$\\\\beta_1$')\n",
    "plt.ylabel('$\\\\beta_0$')\n",
    "plt.xlim(-.05, .15)\n",
    "plt.ylim(-2, 6)\n",
    "plt.title('Nonaugmented Posterior Joint Distribution Approximation for $\\\\beta_0$ and $\\\\beta_1$')\n",
    "plt.show()\n",
    "\n",
    "## PRINT THE SAMPLE COVARIANCES FOR THE CORRESPONDING PLOTS IN THE \n",
    "\n",
    "print('Covariance for nonaugmented joint posterior: ', np.cov(beta0Distribution, beta1Distribution))\n",
    "# fprintf('Covariance for nonaugmented joint posterior: )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mean regression lines for augmented and nonaugmented posterior distributions\n",
    "\n",
    "x = np.linspace(np.min(deadAge), np.max(deadAge), 1000)\n",
    "meanAugmentedB0 = np.mean(jointPosteriorApprox[:, 0])\n",
    "meanAugmentedB1 = np.mean(jointPosteriorApprox[:, 1])\n",
    "plt.plot(x, meanAugmentedB0 + meanAugmentedB1 * x, color = 'r', label = 'Augmented')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Log Survival Time')\n",
    "plt.title('Mean Regression Lines for Nonaugmented and Augmented Analysis')\n",
    "\n",
    "meanNonaugmentedB0 = np.mean(nonAugmentedPosteriorApprox[:, 0])\n",
    "meanNonaugmentedB1 = np.mean(nonAugmentedPosteriorApprox[:, 1])\n",
    "plt.plot(x, meanNonaugmentedB0 + meanNonaugmentedB1 * x, color = 'blue', label = 'Nonaugmented')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the exponential transformation\n",
    "\n",
    "plt.plot(x, np.exp(meanAugmentedB0 + meanAugmentedB1 * x), color = 'r', label = 'Augmented')\n",
    "plt.plot(x, np.exp(meanNonaugmentedB0 + meanNonaugmentedB1 * x), color = 'blue', label = 'Nonaugmented')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Survival Time')\n",
    "plt.legend()\n",
    "plt.title('Exponential Transformation for Nonaugmented and Augmented Regression Lines')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentedBeta1Posterior = jointPosteriorApprox[:, 1]\n",
    "augmentedBeta0Posterior = jointPosteriorApprox[:, 0]\n",
    "augmentedSigmaSqPosterior = jointPosteriorApprox[:, -1]\n",
    "\n",
    "# Sample the posterior for the nonaugmented data\n",
    "\n",
    "plt.hist(augmentedBeta1Posterior, bins = 30, density = True, color = 'skyblue', edgecolor = 'black', alpha = .5, label = 'augmented')\n",
    "nonAugmentedBeta1Posterior = nonAugmentedPosteriorApprox[:, 1]\n",
    "plt.hist(nonAugmentedBeta1Posterior, bins = 30, density = True, color = 'red', edgecolor = 'black', alpha = .5, label = 'nonaugmented')\n",
    "plt.rc('text', usetex = True)\n",
    "plt.xlabel('$\\\\beta_1$')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Comparing Posterior Distributions for Slope of Linear Regression Model')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.hist(augmentedBeta0Posterior, bins = 30, density = True, color = 'skyblue', edgecolor = 'black', alpha = .5, label = 'augmented')\n",
    "nonAugmentedBeta0Posterior = nonAugmentedPosteriorApprox[:, 0]\n",
    "plt.hist(nonAugmentedBeta0Posterior, bins = 30, density = True, color = 'red', edgecolor = 'black', alpha = .5, label = 'nonaugmented')\n",
    "plt.rc('text', usetex = True)\n",
    "plt.xlabel('$\\\\beta_0$')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Comparing Posterior Distributions for Intercept of Linear Regression Model')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.hist(augmentedSigmaSqPosterior, bins = 30, density = True, color = 'skyblue', edgecolor = 'black', alpha = .5, label = 'augmented')\n",
    "nonAugmentedSigmaSqPosterior = nonAugmentedPosteriorApprox[:, -1]\n",
    "plt.hist(nonAugmentedSigmaSqPosterior, bins = 30, density = True, color = 'red', edgecolor = 'black', alpha = .5, label = 'nonaugmented')\n",
    "plt.rc('text', usetex = True)\n",
    "plt.xlabel('$\\\\sigma^2$')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Comparing Posterior Distributions for Error Variance of Linear Regression Model')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "## overlay the posterior distribution without the augmented data with the posterior distribution with the augmented data\n",
    "\n",
    "## plot the mean regression line for the augmented posterior (mean of b0 and b1) next to the mean regression line for the non augmented posterior\n",
    "# which is just the least squares estimate that you got before the algorithm, compare the differences \n",
    "\n",
    "# Can look at more examples for data augmentation, or can look at the math behind convergence, or can DO CARD SHUFFLING ANALYSIS!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
